
from bs4 import BeautifulSoup
from urllib.request import urlopen
import pandas as pd
import numpy as np
import datetime




url="https://www.agribank.com.vn/vn/lai-suat"

soup = BeautifulSoup(urlopen(url).read())
rows =[]
for tr in soup.findAll('table')[1].findAll('tr'):
    print (tr)
    rows.append([td.get_text(strip=True) for td in tr.select('th, td')])
np.array(rows)[1:,:]
LAI_SUAT_AGRIBANK = pd.DataFrame(np.array(rows)[1:,:],columns=rows[0])
LAI_SUAT_AGRIBANK['Update_date'] = datetime.date.today()
LAI_SUAT_AGRIBANK['PRIMARY_KEY'] = LAI_SUAT_AGRIBANK['VND']+LAI_SUAT_AGRIBANK['Update_date'].astype(str)
new_header = LAI_SUAT_AGRIBANK.iloc[0]
LAI_SUAT_AGRIBANK = LAI_SUAT_AGRIBANK[0:]
LAI_SUAT_AGRIBANK.columns='Kỳ hạn','VND','USD','EUR','Update_date','PRIMARY_KEY'

LAI_SUAT_AGRIBANK.to_csv('out/tables/LAI_SUAT_AGRIBANK.csv', index = False,encoding='utf-8')

